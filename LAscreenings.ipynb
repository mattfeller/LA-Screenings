{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOW TO USE: User input is contain in this first python cell below. Edit the starting_urls to the urls of whichever letterboxd watchlists or lists you are interested in exploring. You can add as many urls as you would like to the list.\n",
    "\n",
    "Once you have edited the starting_urls, simply hit \"run all\" and then scroll down to the bottom to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_urls = ['https://letterboxd.com/fella/watchlist/', 'https://letterboxd.com/fella/films/rated/4-5/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not edit below this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "import re\n",
    "from datetime import datetime\n",
    "from thefuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Revival Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of next three months and their corresponding years. For example, if the current month is november 2024, then months = [11, 12, 1] and years = [2024, 2024, 2025]. We use these below to create the required urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3], [2024, 2024, 2024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_month = datetime.now().month\n",
    "current_year = datetime.now().year\n",
    "\n",
    "months = [((current_month + i-1) % 12) + 1 for i in range(3)]\n",
    "\n",
    "years = [current_year for i in range(3)]\n",
    "\n",
    "if current_month >= 11:\n",
    "    years[2] = current_year + 1\n",
    "    if current_month == 12:\n",
    "        years[1] = current_year + 1\n",
    "\n",
    "months, years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the urls and save the html code from those pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_url(month, year):\n",
    "    month_str = str(month)\n",
    "    month_str = month_str.rjust(2, '0')\n",
    "    year_str = str(year)\n",
    "    url = 'https://www.revivalhubla.com/film-calendar?view=calendar&month=' + month_str + '-' + year_str\n",
    "    return url\n",
    "\n",
    "urls = [make_url(month, year) for month, year in zip(months, years)]\n",
    "pages = [urlopen(url) for url in urls]\n",
    "htmls = [page.read().decode(\"utf-8\") for page in pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie titles in the html for Revival Hub's calendar page are between h1 html tags, so we find all instances of that pattern and remove the extraneous html from each, leaving a list of strings containing the movie titles and release years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"<h1>.*?</h1>\"\n",
    "results = [re.findall(pattern, html) for html in htmls]\n",
    "\n",
    "def extract_text(line):\n",
    "    html_chunks = re.findall(\"<.*?>\", line)\n",
    "    for chunk in html_chunks:\n",
    "        line = line.replace(chunk, '')\n",
    "    return line\n",
    "\n",
    "titles = [list(map(extract_text, result)) for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Letterboxd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the starting_url is on page n > 1 of the given list, we remove page/n/ from the urls to start with page 1 instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_urls = len(starting_urls)\n",
    "\n",
    "for i in range(num_of_urls):\n",
    "    while 'page/' in starting_urls[i]:\n",
    "        starting_url[i] = re.sub('page/.*/', '', starting_url[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letterboxd was not happy with the default user agent in urlopen, so we have to spoof a user browser to scrape from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "reqs = [Request(url=starting_url, headers=headers) for starting_url in starting_urls]\n",
    "first_htmls = [urlopen(req).read().decode(\"utf-8\") for req in reqs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first_htmls only contains the first page, containing up to 100 movies, of each list. We start by extracting the total number of pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_pages = '<div class=\"pagination\">.*?</div> </div>'\n",
    "result_pages = [re.findall(pattern_pages, first_html) for first_html in first_htmls]\n",
    "\n",
    "def extract_page_number(text):\n",
    "    if '&hellip;' in text:\n",
    "        str_num = text.split('&hellip;')[-1]\n",
    "    else:\n",
    "        str_num = text.split()[-1]\n",
    "    num = int(str_num)\n",
    "    return num\n",
    "\n",
    "page_count = [1 for i in range(num_of_urls)]\n",
    "\n",
    "for i in range(num_of_urls):    \n",
    "    if result_pages[i]:\n",
    "        pages_text = extract_text(result_pages[i][0])\n",
    "        page_count[i] = extract_page_number(pages_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the page_count, get the html code for each remaining page, combining these with the first html pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_urls = []\n",
    "\n",
    "for j in range(num_of_urls):\n",
    "    remaining_urls += [starting_urls[j] + 'page/' + str(i) + '/' for i in range(2, page_count[j] + 1)]\n",
    "\n",
    "remaining_reqs = [Request(url=rem_url, headers=headers) for rem_url in remaining_urls]\n",
    "remaining_htmls = [urlopen(req).read().decode(\"utf-8\") for req in remaining_reqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_html = ''\n",
    "\n",
    "for html in first_htmls + remaining_htmls:\n",
    "    mega_html = mega_html + html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract the movie titles from this mega_html string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "letterboxd_title_pattern = 'data-film-slug=\".*?\"'\n",
    "slugs = re.findall(letterboxd_title_pattern, mega_html)\n",
    "all_movies = [slug.replace('data-film-slug=\"','').replace('\"','') for slug in slugs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all_movies and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(revival_titles, letterboxd_movies):\n",
    "    matches = []\n",
    "    for movie in letterboxd_movies:\n",
    "        new_match = process.extractOne(movie, revival_titles, score_cutoff=86)\n",
    "        if new_match:\n",
    "            matches.append(new_match)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yi Yi - 2000\n",
      "In the Mood for Love - 2000 / Punch-Drunk Love - 2002\n",
      "In the Mood for Love - 2000 / Punch-Drunk Love - 2002\n",
      "Chungking Express - 1994\n",
      "Twin Peaks: Fire Walk with Me - 1992\n",
      "Hoop Dreams - 1994\n",
      "Frances Ha - 2013\n",
      "Taipei Story - 1985 / In Our Time - 1982\n",
      "Stranger Than Paradise - 1984\n",
      "A Woman Under the Influence - 1974\n",
      "The Seventh Seal - 1957\n"
     ]
    }
   ],
   "source": [
    "this_month = [x[0] for x in find_matches(titles[0], all_movies)]\n",
    "\n",
    "for s in this_month:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Diving Bell and the Butterfly - 2007\n"
     ]
    }
   ],
   "source": [
    "this_month = [x[0] for x in find_matches(titles[1], all_movies)]\n",
    "\n",
    "for s in this_month:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month after next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_month = [x[0] for x in find_matches(titles[2], all_movies)]\n",
    "\n",
    "for s in this_month:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
